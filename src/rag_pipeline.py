"""
PAGEGENERAL - RAG Pipeline (Day 2)
PDF â†’ LLM Extraction â†’ Chromadb
"""

from pathlib import Path
import sys
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.pdf_parser import PDFParser
from src.division_extractor import DivisionExtractor
from src.chunker import SmartChunker
from src.vector_store import VectorStore
from src.llm import OllamaClient
import config
import json
from datetime import datetime


class RAGPipeline:
    """Ana RAG sistemi: PDF â†’ LLM Extraction â†’ Chromadb"""

    def __init__(self, book_name: str, book_id: str):
        self.book_name = book_name
        self.book_id = book_id

        self.parser = PDFParser()
        self.extractor = DivisionExtractor(config.DIVISION_LIST)
        self.chunker = SmartChunker(book_name, book_id)
        self.vs = VectorStore()
        self.llm = OllamaClient()

    def ingest_pdf(self, pdf_path: str | Path) -> dict:
        """
        TÃ¼m pipeline: PDF â†’ Chromadb

        Args:
            pdf_path: PDF dosyasÄ±nÄ±n yolu

        Returns:
            {
                "status": "success" | "error",
                "divisions_found": ["4. Piyade TÃ¼meni", ...],
                "total_paragraphs": 150,
                "chunks_created": 120,
                "error": (varsa)
            }
        """
        pdf_path = Path(pdf_path)

        try:
            # 1. PDF parse
            if config.VERBOSE:
                print(f"\nğŸ“„ ADIM 1: PDF Parse Ediliyor...")

            parse_result = self.parser.parse(pdf_path)

            if parse_result['status'] != 'success':
                return {
                    "status": "error",
                    "error": parse_result.get('error')
                }

            content = parse_result['content']

            # 2. Paragraf bÃ¶l
            if config.VERBOSE:
                print(f"\nâœ‚ï¸  ADIM 2: Paragraf BÃ¶lÃ¼nÃ¼yor...")

            paragraphs = content.split('\n\n')
            paragraphs = [p.strip() for p in paragraphs if p.strip()]

            if config.VERBOSE:
                print(f"   {len(paragraphs)} paragraf bulundu")

            # 3. LLM-based extraction
            if config.VERBOSE:
                print(f"\nğŸ¤– ADIM 3: LLM ile Division Extraction...")

            extraction_results = self.extractor.extract(paragraphs, verbose=True)

            # 4. Chunks oluÅŸtur + metadata
            if config.VERBOSE:
                print(f"\nğŸ“¦ ADIM 4: Chunks OluÅŸturuluyor...")

            chunks = self.chunker.create_chunks(extraction_results)

            if not chunks:
                return {
                    "status": "error",
                    "error": "HiÃ§ chunk oluÅŸturulamadÄ±"
                }

            # 5. Embeddings + Chromadb
            if config.VERBOSE:
                print(f"\nğŸ”— ADIM 5: Chromadb'ye YÃ¼kleniyor...")

            self.vs.ingest_chunks(chunks)

            # 6. Ä°statistikler
            divisions = set()
            for chunk in chunks:
                # division STRING'dir, split et!
                division_str = chunk["metadata"]["division"]

                # VirgÃ¼lle ayrÄ±lmÄ±ÅŸ division'larÄ± parse et
                if division_str:
                    for div in division_str.split(","):
                        div_clean = div.strip()
                        if div_clean:  # BoÅŸ deÄŸerleri skip et
                            divisions.add(div_clean)

            if config.VERBOSE:
                print(f"\nâœ… TAMAMLANDI!")
                print(f"   TÃ¼menleri: {list(divisions)}")
                print(f"   Chunks: {len(chunks)}")

            return {
                "status": "success",
                "divisions_found": sorted(list(divisions)),
                "total_paragraphs": len(paragraphs),
                "chunks_created": len(chunks),
                "book_name": self.book_name,
                "book_id": self.book_id
            }

        except Exception as e:
            return {
                "status": "error",
                "error": str(e)
            }


def main():
    """Test: PDF yÃ¼kle ve query et"""

    # Config
    book_name = "TÃ¼rk Ä°stiklal Harbi - Mondros MÃ¼tarekesi"
    book_id = "turk_istiklal_harbi_mondros"

    pipeline = RAGPipeline(book_name, book_id)

    # PDF'leri bul
    pdf_files = list(config.INPUT_DIR.glob("*.pdf"))

    if not pdf_files:
        print(f"âŒ {config.INPUT_DIR} klasÃ¶rÃ¼nde PDF bulunamadÄ±!")
        return

    print(f"\nğŸ–ï¸  PAGEGENERAL - PDF â†’ LLM â†’ Chromadb\n")
    print(f"ğŸ“‚ {len(pdf_files)} PDF bulundu\n")

    # Ä°lk PDF'i yÃ¼kle
    pdf_file = pdf_files[0]
    print(f"ğŸ“¥ YÃ¼kleniyor: {pdf_file.name}\n")

    ingest_result = pipeline.ingest_pdf(pdf_file)

    if ingest_result['status'] != 'success':
        print(f"\nâŒ Hata: {ingest_result['error']}")
        return

    print(f"\n" + "=" * 60)
    print(f"ğŸ“Š SONUÃ‡LAR:")
    print(f"=" * 60)
    print(f"âœ… TÃ¼menleri: {', '.join(ingest_result['divisions_found'])}")
    print(f"ğŸ“ Toplam Paragraf: {ingest_result['total_paragraphs']}")
    print(f"ğŸ“¦ OluÅŸturulan Chunks: {ingest_result['chunks_created']}")
    print(f"=" * 60)


if __name__ == "__main__":
    main()