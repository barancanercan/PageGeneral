"""
PAGEGENERAL - LLM Client
Ollama (qwen2.5:7b) ile iletiÅŸim
"""

import requests
import config


class OllamaClient:
    """Ollama LLM ile baÄŸlantÄ±"""

    def __init__(self, base_url: str = None, model: str = None):
        self.base_url = base_url or config.OLLAMA_BASE_URL
        self.model = model or config.LLM_MODEL
        self.endpoint = f"{self.base_url}/api/generate"

    def is_available(self) -> bool:
        """Ollama sunucusu aÃ§Ä±k mÄ± kontrol et"""
        try:
            response = requests.get(f"{self.base_url}/api/tags", timeout=2)
            return response.status_code == 200
        except:
            return False

    def generate(self, prompt: str, temperature: float = None,
                 max_tokens: int = None) -> str:
        """
        Ollama'dan yanÄ±t al

        Args:
            prompt: Ä°stek
            temperature: YaratÄ±cÄ±lÄ±k (0.0-1.0)
            max_tokens: Maksimum yanÄ±t uzunluÄŸu

        Returns:
            Model yanÄ±tÄ± (string)
        """
        if temperature is None:
            temperature = config.LLM_TEMPERATURE
        if max_tokens is None:
            max_tokens = config.LLM_MAX_TOKENS

        payload = {
            "model": self.model,
            "prompt": prompt,
            "temperature": temperature,
            "num_predict": max_tokens,
            "stream": False
        }

        try:
            if config.VERBOSE:
                print(f"ğŸ¤– LLM'ye soruluyor ({self.model})...")

            response = requests.post(self.endpoint, json=payload, timeout=300)
            response.raise_for_status()

            result = response.json()
            return result.get('response', '').strip()

        except requests.exceptions.ConnectionError:
            print("âŒ HATA: Ollama sunucusu Ã§alÄ±ÅŸmÄ±yor!")
            print("   LÃ¼tfen ÅŸunu Ã§alÄ±ÅŸtÄ±rÄ±n: ollama serve")
            return ""

        except requests.exceptions.Timeout:
            print("â±ï¸  HATA: Ollama timeout (Ã§ok yavaÅŸ)")
            return ""

        except Exception as e:
            print(f"âŒ LLM HatasÄ±: {e}")
            return ""


def test_connection():
    """Ollama baÄŸlantÄ±sÄ±nÄ± test et"""
    client = OllamaClient()

    print("ğŸ”— Ollama baÄŸlantÄ±sÄ± test ediliyor...")

    if client.is_available():
        print(f"âœ… Ollama aÃ§Ä±k: {client.base_url}")
        print(f"ğŸ“¦ Model: {client.model}")

        # Basit test
        response = client.generate("Merhaba, ne yapÄ±yorsun?")
        if response:
            print(f"ğŸ’¬ YanÄ±t: {response[:100]}...")
        else:
            print("âŒ Model yanÄ±t vermedi")
    else:
        print(f"âŒ Ollama aÃ§Ä±k deÄŸil: {client.base_url}")
        print("   Ã‡alÄ±ÅŸtÄ±r: ollama serve")


if __name__ == "__main__":
    test_connection()