"""
PAGEGENERAL - Smart Chunker
Extraction sonuÃ§larÄ±ndan â†’ Chunks + Metadata (Berke formatÄ±)
"""

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent))

import config
from datetime import datetime
from typing import List, Dict


class SmartChunker:
    """Extraction â†’ Chunks with metadata"""

    def __init__(self, book_name: str, book_id: str):
        self.book_name = book_name
        self.book_id = book_id

    def create_chunks(self, extraction_results: List[Dict], chunk_size: int = 512):
        """
        Extraction'dan chunks yap + Berke formatÄ±nda metadata ekle

        Args:
            extraction_results: Division Extractor output
            chunk_size: Token cinsinden chunk boyutu

        Returns:
            List[{
                "id": "parag_5",
                "document": "...",
                "metadata": {
                    "division": ["4. Piyade TÃ¼meni"],
                    "confidence": 0.95,
                    "source_page": 14,
                    "book_name": "...",
                    "book_id": "..."
                }
            }]
        """

        chunks = []

        for result in extraction_results:
            # Confidence filter
            if result["confidence"] < config.EXTRACTION_CONFIDENCE_THRESHOLD:
                continue

            # BoÅŸ division skip et
            if not result["divisions"]:
                continue

            para_id = result["para_id"]
            chunk_id = f"parag_{para_id}"

            # Metadata oluÅŸtur
            metadata = {
                "division": ", ".join(result["divisions"]),  # â† STRING (DOÄžRU!)
                "confidence": result["confidence"],
                "source_page": self._calculate_page(para_id),
                "book_name": self.book_name,
                "book_id": self.book_id,
                "para_id": para_id,
                "timestamp": datetime.now().isoformat()
            }

            # Chunk oluÅŸtur (Berke formatÄ±)
            chunk = {
                "id": chunk_id,
                "document": result["text"],
                "metadata": metadata
            }

            chunks.append(chunk)

        if config.VERBOSE:
            print(f"âœ‚ï¸  {len(chunks)} chunk oluÅŸturuldu")

        return chunks

    def _calculate_page(self, para_id: int) -> int:
        """Para ID'den sayfa numarasÄ±nÄ± bul (basit: 50 para/sayfa)"""
        return (para_id // 50) + 1


def test_chunker():
    """Test: chunking Ã§alÄ±ÅŸÄ±yor mu?"""

    print("ðŸ§ª Smart Chunker Test\n")

    # Mock extraction results
    mock_results = [
        {
            "para_id": 5,
            "text": "4. Piyade TÃ¼meni komutanÄ±, cepheye gitmek Ã¼zere hazÄ±rlanÄ±yordu.",
            "divisions": ["4. Piyade TÃ¼meni"],
            "confidence": 0.95
        },
        {
            "para_id": 15,
            "text": "9. Piyade TÃ¼meni ile 24. Piyade TÃ¼meni ortak operasyon yapacaklardÄ±.",
            "divisions": ["9. Piyade TÃ¼meni", "24. Piyade TÃ¼meni"],
            "confidence": 0.92
        },
        {
            "para_id": 20,
            "text": "Hava Ã§ok soÄŸuktu.",
            "divisions": [],  # No division
            "confidence": 0.0
        }
    ]

    chunker = SmartChunker(
        book_name="TÃ¼rk Ä°stiklal Harbi - Mondros MÃ¼tarekesi",
        book_id="turk_istiklal_harbi_mondros"
    )

    chunks = chunker.create_chunks(mock_results)

    print(f"ðŸ“Š {len(chunks)} chunk oluÅŸturuldu\n")

    for i, chunk in enumerate(chunks, 1):
        print(f"Chunk {i}:")
        print(f"  ID: {chunk['id']}")
        print(f"  Divisions: {chunk['metadata']['division']}")
        print(f"  Confidence: {chunk['metadata']['confidence']:.0%}")
        print(f"  Page: {chunk['metadata']['source_page']}")
        print(f"  Text: {chunk['document'][:60]}...")
        print()

    print("âœ… Test tamamlandÄ±")


if __name__ == "__main__":
    test_chunker()